{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Holy-Morphism/GenAI/blob/main/TextAugmentor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Augmenter\n",
        "\n",
        "## Install libraries"
      ],
      "metadata": {
        "id": "6hqFqQaNbQgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFEBjZlzSQ2M",
        "outputId": "b78e238e-2e49-4eae-95df-77cc7ff91fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Collecting git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git\n",
            "  Cloning https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git to /tmp/pip-req-build-657z54rn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git /tmp/pip-req-build-657z54rn\n",
            "  Resolved https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git to commit 03084c54b64019ba5fa0b620b9c70ad81123e458\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from parrot==1.0) (4.42.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from parrot==1.0) (0.1.99)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from parrot==1.0) (0.25.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from parrot==1.0) (3.0.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from parrot==1.0) (0.18.0)\n",
            "Requirement already satisfied: Levenshtein==0.25.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->parrot==1.0) (0.25.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.25.1->python-Levenshtein->parrot==1.0) (3.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->parrot==1.0) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->parrot==1.0) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->parrot==1.0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->parrot==1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->parrot==1.0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers->parrot==1.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->parrot==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->parrot==1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->parrot==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->parrot==1.0) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->parrot==1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->parrot==1.0) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->parrot==1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->parrot==1.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "Y3DKxTZkbadV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# paraphrasing\n",
        "from parrot import Parrot\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3OrrtGb8TRqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Parrot"
      ],
      "metadata": {
        "id": "NpWcNX4Xbdob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")"
      ],
      "metadata": {
        "id": "2VbSvLRVXEb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Augmenter Class"
      ],
      "metadata": {
        "id": "nxvVQv-6bgTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkfNkwlnSQ2N"
      },
      "outputs": [],
      "source": [
        "class TextAugmenter:\n",
        "    def __init__(self, data_path, output_path, parrot):\n",
        "        self.data_path = data_path\n",
        "        self.output_path = output_path\n",
        "        self.data = self.load_data()\n",
        "        self.parrot = parrot\n",
        "\n",
        "    def load_data(self):\n",
        "        with open(self.data_path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def save_data(self):\n",
        "        with open(self.output_path, \"w\") as f:\n",
        "            json.dump(self.data, f, indent=4)\n",
        "\n",
        "    def get_synonyms(self, word):\n",
        "        \"\"\"\n",
        "        Returns a list of synonyms for a given word.\n",
        "        \"\"\"\n",
        "        synonyms = set()\n",
        "        for syn in wordnet.synsets(word):\n",
        "            for l in syn.lemmas():\n",
        "                synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "                synonyms.add(synonym)\n",
        "        return list(synonyms)\n",
        "\n",
        "    def apply_to_data(self, function, **kwargs):\n",
        "        \"\"\"\n",
        "        Applies a given function to the 'text' field of each data item.\n",
        "        \"\"\"\n",
        "        for item in self.data:\n",
        "            item[\"text\"] = function(item[\"text\"], **kwargs)\n",
        "\n",
        "    def random_deletion(self, text, p=0.2):\n",
        "        \"\"\"\n",
        "        Randomly deletes words from a sentence with probability p.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        if len(words) == 1:\n",
        "            return text\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            r = random.uniform(0, 1)\n",
        "            if r > p:\n",
        "                new_words.append(word)\n",
        "        return \" \".join(new_words)\n",
        "\n",
        "    def random_insertion(self, text, p=0.2):\n",
        "        \"\"\"\n",
        "        Randomly inserts synonyms into a sentence with probability p.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        new_words = []\n",
        "        for word in words:\n",
        "            r = random.uniform(0, 1)\n",
        "            if r < p:\n",
        "                synonyms = self.get_synonyms(word)\n",
        "                if synonyms:\n",
        "                    new_words.append(random.choice(synonyms))\n",
        "            new_words.append(word)\n",
        "        return \" \".join(new_words)\n",
        "\n",
        "    def paraphrase(self, text):\n",
        "        paraphrases = self.parrot.augment(input_phrase= text,\n",
        "                               use_gpu=True,\n",
        "                               do_diverse=True,             # Enable this to get more diverse paraphrases\n",
        "                               adequacy_threshold = 0.50,   # Lower this numbers if no paraphrases returned\n",
        "                               fluency_threshold = 0.80)\n",
        "        if paraphrases:\n",
        "            return paraphrases[0][0]  # Extract the paraphrased string\n",
        "        else:\n",
        "            return text  # Return original text if no paraphrase is generated\n",
        "\n",
        "    def synonym_replacement(self, text, p=0.2):\n",
        "        \"\"\"\n",
        "        Replaces words with synonyms with probability p.\n",
        "        \"\"\"\n",
        "        words = word_tokenize(text)\n",
        "        new_words = []\n",
        "        for word, tag in pos_tag(words):\n",
        "            r = random.uniform(0, 1)\n",
        "            if r < p:\n",
        "                synonyms = self.get_synonyms(word)\n",
        "                if synonyms:\n",
        "                    new_words.append(random.choice(synonyms))\n",
        "                else:\n",
        "                    new_words.append(word)\n",
        "            else:\n",
        "                new_words.append(word)\n",
        "        return \" \".join(new_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAdcli0FSQ2O"
      },
      "outputs": [],
      "source": [
        "augmenter = TextAugmenter(\"announcements.json\", \"augmented_data.json\", parrot)\n",
        "\n",
        "augmenter.apply_to_data(augmenter.paraphrase)  # Apply random deletion\n",
        "augmenter.save_data()  # Save intermediate result (optional)\n",
        "\n",
        "# augmenter.apply_to_data(augmenter.random_deletion, p=0.1)  # Apply random deletion\n",
        "# augmenter.save_data()  # Save intermediate result (optional)\n",
        "\n",
        "\n",
        "\n",
        "# augmenter.apply_to_data(augmenter.random_insertion, p=0.1)  # Apply random insertion\n",
        "# augmenter.save_data()  # Save intermediate result (optional)\n",
        "\n",
        "# # ... apply other functions in a similar way\n",
        "\n",
        "# augmenter.apply_to_data(augmenter.synonym_replacement, p=0.2)  # Apply synonym replacement\n",
        "# augmenter.save_data()  # Save final result"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}